{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# This Notebook is the starting of Capstone Project\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Users/yazeed/.conda/envs/Test/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import random\n",
    "import numpy as np\n",
    "from textwrap import wrap\n",
    "from datetime import date, datetime\n",
    "import datetime as dt\n",
    "from xgboost import XGBClassifier\n",
    "from rfpimp import *\n",
    "import pandas as pd\n",
    "import researchpy as rp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from geopy.distance import geodesic\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from geopy.distance import great_circle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "%matplotlib\n",
    "FIGS_DIR = 'figs/'\n",
    "LabelName='SEVERITYCODE'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def train_test(df):\n",
    "    # Get the Dependent and Independent Features.\n",
    "    X = df.drop([LabelName], axis=1)\n",
    "    y = df[LabelName]\n",
    "\n",
    "    # Split into 90% train and 10% test\n",
    "    return train_test_split(X, y, test_size=0.10, shuffle=True, stratify=y)\n",
    "def XGB(df):\n",
    "    \n",
    "    # Split to train test.. 90% <-> 10% (not shuffled)\n",
    "    X_train, X_test, y_train, y_test = train_test(df)\n",
    "    print(\"Features:\\n\" + str(df.dtypes))\n",
    "    print(\"Start Training...\")\n",
    "    lr_list = [0.1]\n",
    "    n_estimators = [128]\n",
    "    max_depth = [3,10,2]\n",
    "    subsample=[0.8]\n",
    "    min_child_weight=[1,6,2]\n",
    "    gamma=[0,0.3]\n",
    "    colsample_bytree=[0.8]\n",
    "    scale_pos_weight=[1]\n",
    "\n",
    "\n",
    "\n",
    "    search_grid = {\n",
    "                   'eta': lr_list,\n",
    "                   'n_estimators': n_estimators,\n",
    "                   'min_child_weight':min_child_weight,\n",
    "                   'gamma':gamma,\n",
    "                   'colsample_bytree':colsample_bytree,\n",
    "                   'scale_pos_weight':scale_pos_weight,\n",
    "                   'max_depth': max_depth,\n",
    "                   'subsample': subsample}\n",
    "    pprint(search_grid)\n",
    "\n",
    "    rf = XGBClassifier()\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=search_grid, cv=10, verbose=2,\n",
    "                                    n_jobs=-3, scoring='f1')\n",
    "\n",
    "\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    pprint(grid_search.best_params_)\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "    best_grid = grid_search.best_estimator_\n",
    "    res=best_grid.predict(X_test)\n",
    "    print(confusion_matrix(y_test,res))\n",
    "    print(f1_score(y_test,res))\n",
    "def randomForest(df):\n",
    "    \n",
    "    # Split to train test.. 90% <-> 10% (not shuffled)\n",
    "    X_train, X_test, y_train, y_test = train_test(df)\n",
    "    print(\"Features:\\n\" + str(df.dtypes))\n",
    "    print(\"Start Training...\")\n",
    "    # Parameters\n",
    "    # Number of trees in random forest\n",
    "   # n_estimators = [int(x) for x in np.linspace(start=64, stop=1024, num=10)]\n",
    "    n_estimators =[64]\n",
    "\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto']\n",
    "    # Maximum number of levels in tree\n",
    "    #max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "    max_depth =[40]\n",
    "    #max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [ 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [ 65]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True]\n",
    "    # Create the random grid\n",
    "    search_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    pprint(search_grid)\n",
    "\n",
    "\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=search_grid, cv=10, verbose=2,\n",
    "                                    n_jobs=-3, scoring='f1')\n",
    "\n",
    "\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    pprint(grid_search.best_params_)\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "    best_grid = grid_search.best_estimator_\n",
    "    res=best_grid.predict(X_test)\n",
    "    cm= confusion_matrix(y_test,res)\n",
    "    print(f1_score(y_test,res))\n",
    "    print(accuracy_score(y_test,res))\n",
    "    labels = ['Code 1', 'Code 2']\n",
    "    print(cm)\n",
    "    plot_confusion_matrix(best_grid,X_test, y_test)\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig(FIGS_DIR + 'cm' + '.png', pad_inches=50)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Model Methods\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def underSample(df):\n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "    X = df.drop([LabelName], axis=1)\n",
    "    y = df[LabelName]\n",
    "    X_under, y_under = undersample.fit_resample(X, y)\n",
    "    y_under = y_under.to_frame(name=LabelName)\n",
    "    X_under[LabelName]= y_under\n",
    "    \n",
    "    return X_under\n",
    "    \n",
    "    \n",
    "def buildFreqChart(df, colName):\n",
    "    x = df[colName].unique()\n",
    "    numValues = x.shape[0]\n",
    "    arr1 = np.empty(numValues, dtype=float)\n",
    "    arr2 = np.empty(numValues, dtype=float)\n",
    "    totalArr = np.empty(numValues, dtype=float)\n",
    "    index = 0\n",
    "    numTotal = df.shape[0]\n",
    "    xindex = 0\n",
    "    for i in x:\n",
    "        isNan = False\n",
    "        try:\n",
    "            if np.math.isnan(float(i)):\n",
    "                isNan = True\n",
    "                x[xindex] = '#NAN'\n",
    "        except:\n",
    "            isNan = False\n",
    "        xindex = xindex + 1\n",
    "        if isNan:\n",
    "            df1 = df.loc[df[colName].isnull()]\n",
    "        else:\n",
    "            df1 = df.loc[df[colName] == i]\n",
    "        numOfRows = df1.shape[0]\n",
    "\n",
    "        dfc1 = df1.loc[df1[LabelName] == 1]\n",
    "        dfc2 = df1.loc[df1[LabelName] == 2]\n",
    "        assert numOfRows == (dfc1.shape[0] + dfc2.shape[0]), \"Sum is not equal!!\"\n",
    "        try:\n",
    "            arr1[index] = (dfc1.shape[0] / numOfRows) * 100\n",
    "        except Exception as e:\n",
    "            print(str(e) + \":\" + colName + \" with \" + str(x))\n",
    "            print(df.head())\n",
    "            exit(0)\n",
    "        arr2[index] = (dfc2.shape[0] / numOfRows) * 100\n",
    "        totalArr[index] = (numOfRows / numTotal) * 100\n",
    "        index = index + 1\n",
    "\n",
    "    plt.figure(figsize=(2 + numValues, 3))\n",
    "\n",
    "    # stack bars\n",
    "    if df.dtypes[colName]== object:\n",
    "     x = [ '\\n'.join(wrap(l, 12)) for l in x ]\n",
    "\n",
    "        \n",
    "    plt.bar(x, arr1, label='Code 1', color='Green', width=0.3)\n",
    "    plt.bar(x, arr2, bottom=arr1, label='Code 2', color='Red', width=0.3)\n",
    "    plt.xticks(fontsize=8)\n",
    "\n",
    "    # add text annotation corresponding to the percentage of each data.\n",
    "    for xpos, ypos, yval in zip(x, arr1 / 2, arr1):\n",
    "        plt.text(xpos, ypos, \"%.1f\" % yval, ha=\"center\", va=\"center\")\n",
    "    for xpos, ypos, yval in zip(x, arr1 + arr2 / 2, arr2):\n",
    "        plt.text(xpos, ypos, \"%.1f\" % yval, ha=\"center\", va=\"center\")\n",
    "\n",
    "    # add text annotation corresponding to the \"total\" value of each bar\n",
    "    for xpos, ypos, yval in zip(x, arr1 + arr2, totalArr):\n",
    "        plt.text(xpos, ypos, \"%.1f%s\" % (yval, \"%\"), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    plt.ylim(0, 110)\n",
    "    plt.legend(bbox_to_anchor=(1.01, 0.5), loc='center left')\n",
    "    plt.xlabel(colName, labelpad=5)\n",
    "    plt.ylabel(\"Percentage\", labelpad=5)\n",
    "    plt.title(\"Severity Code Grouped by \"+colName, y=1.02)\n",
    "\n",
    "def buildFreqChart1(df, colName):\n",
    "    \n",
    "   \n",
    "    x = df[colName].unique()\n",
    "    x.sort()\n",
    "    numValues = x.shape[0]\n",
    "    yArr = np.empty(numValues, dtype=float)\n",
    "    index = 0\n",
    "    for i in x:\n",
    "        count= df.loc[df[colName] == i].shape[0]\n",
    "        yArr[index]= count\n",
    "        index = index + 1\n",
    "        \n",
    "    x= x.astype(str)\n",
    "    plt.figure()\n",
    "    plt.bar(x, yArr,width=0.2, align='center')\n",
    "    for index, value in enumerate(yArr):\n",
    "        plt.text(index-0.04, value, f\"{value:,.0f}\")\n",
    "    \n",
    "    \n",
    "    plt.gca().get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n",
    "    plt.xlabel(\"Severity Code\", labelpad=5)\n",
    "    plt.ylabel(\"Count of Accidents\", labelpad=5)\n",
    "    plt.title(\"Accidents Grouped by Severity Code \", y=1.02) \n",
    "    #plt.savefig(FIGS_DIR + colName + str(random.randint(0,99))+ '.png', bbox_inches='tight', pad_inches=0.02)\n",
    "  \n",
    "def buildBoxPlot(df, colName):\n",
    "\n",
    "    fig = plt.figure(figsize =(10, 7)) \n",
    "    plt.boxplot(df[colName]) \n",
    "    plt.ylabel(colName, labelpad=5)\n",
    "    plt.title(\"Distribution of \" + colName, y=1.02)\n",
    "    plt.savefig(FIGS_DIR + colName + '.png', pad_inches=50)\n",
    "\n",
    "def fixDate(df):\n",
    "    dateCol='INCDATE'\n",
    "    timeCol= 'INCDTTM'\n",
    "    time_format1 = '%I:%M:%S %p'\n",
    "    time_format2 = '%H:%M:%S'\n",
    "    df[dateCol] = pd.to_datetime(df[dateCol], format='%Y/%m/%d')\n",
    "    invalidCount=0\n",
    "    for i in df.index:\n",
    "        date = df[dateCol][i]\n",
    "        time= df[timeCol][i]\n",
    "        df.at[i, 'Month'] = date.strftime(\"%B\")\n",
    "        df.at[i, 'Day'] = date.strftime(\"%a\")\n",
    "        x=time.find(' ')\n",
    "        timeStr= time[x+1:]\n",
    "        hour=-1\n",
    "        try:\n",
    "            hour = datetime.strptime(timeStr, time_format1).time().hour\n",
    "        except ValueError:\n",
    "            try:\n",
    "                hour = datetime.strptime(timeStr, time_format2).time().hour\n",
    "            except ValueError:\n",
    "                invalidCount=invalidCount+1\n",
    "        df.at[i, 'Hour']= hour\n",
    "        \n",
    "    print(\"Accidents with Invalid Time=\"+str(invalidCount))\n",
    "    df['Hour'] = df['Hour'].astype(str)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "    return df\n",
    "\n",
    "def computeCorCat(df, colName):\n",
    "    table, results = rp.crosstab(df[colName], df['SEVERITYCODE'], prop='col', test='chi-square',\n",
    "                                 correction=False)\n",
    "    print(\"Correlation with \"+ colName)\n",
    "    print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Methods \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Hello Capstone Project Course!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('Hello Capstone Project Course!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Main \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Users/yazeed/.conda/envs/Test/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "INPUT_FILE='Data-Collisions.csv'\n",
    "df=pd.read_csv(INPUT_FILE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Read File\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "After Performing Under-sampling:\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "buildFreqChart1(df,LabelName)\n",
    "df= underSample(df)\n",
    "#After Under-sampling\n",
    "print(\"After Performing Under-sampling:\")\n",
    "buildFreqChart1(df,LabelName)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Fix Class Imbalance\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accidents with Invalid Time=48022\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df= fixDate(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Fix date and add time and date features\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Correlation with WEATHER\n",
      "                 Chi-square test    results\n",
      "0  Pearson Chi-square ( 10.0) =   4650.2591\n",
      "1                     p-value =      0.0000\n",
      "2                  Cramer's V =      0.2023\n",
      "Correlation with COLLISIONTYPE\n",
      "                Chi-square test     results\n",
      "0  Pearson Chi-square ( 9.0) =   27468.1108\n",
      "1                    p-value =       0.0000\n",
      "2                 Cramer's V =       0.4915\n",
      "Correlation with ADDRTYPE\n",
      "                Chi-square test    results\n",
      "0  Pearson Chi-square ( 2.0) =   5141.7811\n",
      "1                    p-value =      0.0000\n",
      "2                 Cramer's V =      0.2110\n",
      "Correlation with ROADCOND\n",
      "                Chi-square test    results\n",
      "0  Pearson Chi-square ( 8.0) =   4768.6999\n",
      "1                    p-value =      0.0000\n",
      "2                 Cramer's V =      0.2049\n",
      "Correlation with LIGHTCOND\n",
      "                Chi-square test    results\n",
      "0  Pearson Chi-square ( 8.0) =   4535.6323\n",
      "1                    p-value =      0.0000\n",
      "2                 Cramer's V =      0.1999\n",
      "Correlation with Hour\n",
      "                 Chi-square test   results\n",
      "0  Pearson Chi-square ( 24.0) =   443.0337\n",
      "1                     p-value =     0.0000\n",
      "2                  Cramer's V =     0.0617\n",
      "Correlation with Day\n",
      "                Chi-square test  results\n",
      "0  Pearson Chi-square ( 6.0) =   43.3724\n",
      "1                    p-value =    0.0000\n",
      "2                 Cramer's V =    0.0193\n",
      "Correlation with Month\n",
      "                 Chi-square test  results\n",
      "0  Pearson Chi-square ( 11.0) =   90.3347\n",
      "1                     p-value =    0.0000\n",
      "2                  Cramer's V =    0.0279\n",
      "Correlation with UNDERINFL\n",
      "                Chi-square test   results\n",
      "0  Pearson Chi-square ( 3.0) =   364.6655\n",
      "1                    p-value =     0.0000\n",
      "2                 Cramer's V =     0.0566\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Keep important features\n",
    "\n",
    "catCols=['WEATHER','COLLISIONTYPE',\"ADDRTYPE\",'ROADCOND', 'LIGHTCOND','Hour', 'Day', 'Month', 'UNDERINFL']\n",
    "numCols= [\"PERSONCOUNT\", \"VEHCOUNT\", \"PEDCOUNT\", \"PEDCYLCOUNT\"]\n",
    "df = df.filter(catCols + numCols+ ['SEVERITYCODE'])\n",
    "\n",
    "for i in catCols:\n",
    "    buildFreqChart(df,i)\n",
    "    computeCorCat(df,i)\n",
    "\n",
    "df.describe()\n",
    "df.corr()\n",
    "\n",
    "for i in numCols:\n",
    "    buildBoxPlot(df,i)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Analysis\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df['UNDERINFL'] = df['UNDERINFL'].replace(['1'],'Y')\n",
    "df['UNDERINFL'] = df['UNDERINFL'].replace(['0'],'N')\n",
    "# Fill missing values\n",
    "df[\"UNDERINFL\"] = df[\"UNDERINFL\"].fillna('N')\n",
    "df[\"ROADCOND\"] = df[\"ROADCOND\"].fillna('Dry')\n",
    "df[\"LIGHTCOND\"] = df[\"LIGHTCOND\"].fillna('Daylight')\n",
    "df[\"ADDRTYPE\"] = df[\"ADDRTYPE\"].fillna('Block')\n",
    "df=df.dropna(subset = ['COLLISIONTYPE'])\n",
    "for i in numCols:\n",
    "    df[i].fillna((df[i].mean()), inplace=True)\n",
    "# Remove Outliers\n",
    "df= df[df.PERSONCOUNT<9]\n",
    "df= df[df.VEHCOUNT<5]\n",
    "df= df[df.VEHCOUNT>0]\n",
    "df= df[df.PEDCOUNT<3]\n",
    "df= df[df.PEDCYLCOUNT<2]    \n",
    "df= df.drop(['WEATHER', 'Hour', 'Day', 'Month', 'UNDERINFL'], axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Preprocessing\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Features:\n",
      "PERSONCOUNT                           int64\n",
      "VEHCOUNT                              int64\n",
      "PEDCOUNT                              int64\n",
      "PEDCYLCOUNT                           int64\n",
      "SEVERITYCODE                          int64\n",
      "COLLISIONTYPE_Angles                  uint8\n",
      "COLLISIONTYPE_Cycles                  uint8\n",
      "COLLISIONTYPE_Head On                 uint8\n",
      "COLLISIONTYPE_Left Turn               uint8\n",
      "COLLISIONTYPE_Other                   uint8\n",
      "COLLISIONTYPE_Parked Car              uint8\n",
      "COLLISIONTYPE_Pedestrian              uint8\n",
      "COLLISIONTYPE_Rear Ended              uint8\n",
      "COLLISIONTYPE_Right Turn              uint8\n",
      "COLLISIONTYPE_Sideswipe               uint8\n",
      "ADDRTYPE_Alley                        uint8\n",
      "ADDRTYPE_Block                        uint8\n",
      "ADDRTYPE_Intersection                 uint8\n",
      "ROADCOND_Dry                          uint8\n",
      "ROADCOND_Ice                          uint8\n",
      "ROADCOND_Oil                          uint8\n",
      "ROADCOND_Other                        uint8\n",
      "ROADCOND_Sand/Mud/Dirt                uint8\n",
      "ROADCOND_Snow/Slush                   uint8\n",
      "ROADCOND_Standing Water               uint8\n",
      "ROADCOND_Unknown                      uint8\n",
      "ROADCOND_Wet                          uint8\n",
      "LIGHTCOND_Dark - No Street Lights     uint8\n",
      "LIGHTCOND_Dark - Street Lights Off    uint8\n",
      "LIGHTCOND_Dark - Street Lights On     uint8\n",
      "LIGHTCOND_Dark - Unknown Lighting     uint8\n",
      "LIGHTCOND_Dawn                        uint8\n",
      "LIGHTCOND_Daylight                    uint8\n",
      "LIGHTCOND_Dusk                        uint8\n",
      "LIGHTCOND_Other                       uint8\n",
      "LIGHTCOND_Unknown                     uint8\n",
      "dtype: object\n",
      "Start Training...\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [40],\n",
      " 'max_features': ['auto'],\n",
      " 'min_samples_leaf': [65],\n",
      " 'min_samples_split': [10],\n",
      " 'n_estimators': [64]}\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "{'bootstrap': True,\n",
      " 'max_depth': 40,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 65,\n",
      " 'min_samples_split': 10,\n",
      " 'n_estimators': 64}\n",
      "0.6865765052569058\n",
      "0.6706960421134724\n",
      "0.6998933901918977\n",
      "[[3440 2188]\n",
      " [1190 4438]]\n",
      "DONE\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done   5 out of  10 | elapsed:    7.4s remaining:    7.4s\n",
      "[Parallel(n_jobs=-3)]: Done  10 out of  10 | elapsed:   11.8s finished\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df = pd.get_dummies(df)\n",
    "randomForest(df)\n",
    "print (\"DONE\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Build model and obtain results\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}